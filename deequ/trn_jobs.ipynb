{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SPARK_VERSION=3.0.0\n"
     ]
    }
   ],
   "source": [
    "%env SPARK_VERSION=3.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pydeequ\n",
    "\n",
    "from pyspark.sql import SparkSession, Row\n",
    "\n",
    "# TODO create spark session with jdbc driver path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "server_name = \"jdbc:sqlserver://host.docker.internal\"\n",
    "database_name = \"TRN\"\n",
    "jdbc_url = server_name + \";\" + \"databaseName=\" + database_name + \";trustServerCertificate=True;\"\n",
    "\n",
    "table_name = \"hr.jobs\"\n",
    "username = \"DQTestUser\"\n",
    "password = \"DQTesting111\" # Please specify password here\n",
    "connection_details = { \"user\": username, \"password\": password, \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\", }\n",
    "\n",
    "\n",
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .config(\"spark.jars.packages\", pydeequ.deequ_maven_coord)\n",
    "    .config(\"spark.jars.excludes\", pydeequ.f2j_maven_coord)\n",
    "    .config(\"spark.driver.extraClassPath\", \"/home/jars/sqlserver/sqlserverjdbc.jar\")\n",
    "    .getOrCreate())\n",
    "\n",
    "df = spark.read.jdbc(url=jdbc_url, table=table_name, properties=connection_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- job_id: integer (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      " |-- min_salary: decimal(8,2) (nullable = true)\n",
      " |-- max_salary: decimal(8,2) (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------------------+----------+----------+\n",
      "|job_id|job_title                      |min_salary|max_salary|\n",
      "+------+-------------------------------+----------+----------+\n",
      "|1     |Public Accountant              |4200.00   |9000.00   |\n",
      "|2     |Accounting Manager             |8200.00   |16000.00  |\n",
      "|3     |Administration Assistant       |3000.00   |6000.00   |\n",
      "|4     |President                      |20000.00  |40000.00  |\n",
      "|5     |Administration Vice President  |15000.00  |30000.00  |\n",
      "|6     |Accountant                     |4200.00   |9000.00   |\n",
      "|7     |Finance Manager                |8200.00   |16000.00  |\n",
      "|8     |Human Resources Representative |4000.00   |9000.00   |\n",
      "|9     |Programmer                     |4000.00   |10000.00  |\n",
      "|10    |Marketing Manager              |9000.00   |15000.00  |\n",
      "|11    |Marketing Representative       |4000.00   |9000.00   |\n",
      "|12    |Public Relations Representative|4500.00   |10500.00  |\n",
      "|13    |Purchasing Clerk               |2500.00   |5500.00   |\n",
      "|14    |Purchasing Manager             |8000.00   |15000.00  |\n",
      "|15    |Sales Manager                  |10000.00  |20000.00  |\n",
      "|16    |Sales Representative           |6000.00   |12000.00  |\n",
      "|17    |Shipping Clerk                 |2500.00   |5500.00   |\n",
      "|18    |Stock Clerk                    |2000.00   |5000.00   |\n",
      "|19    |Stock Manager                  |5500.00   |8500.00   |\n",
      "+------+-------------------------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------------+------------------+\n",
      "| entity|  instance|               name|             value|\n",
      "+-------+----------+-------------------+------------------+\n",
      "| Column|    job_id|       Completeness|               1.0|\n",
      "| Column|    job_id|ApproxCountDistinct|              19.0|\n",
      "| Column|max_salary|         Compliance|               0.0|\n",
      "| Column| job_title|ApproxCountDistinct|              18.0|\n",
      "| Column|min_salary|               Mean| 6568.421052631579|\n",
      "|Dataset|         *|               Size|              19.0|\n",
      "| Column|max_salary|               Mean|13210.526315789473|\n",
      "| Column|min_salary|         Compliance|               1.0|\n",
      "+-------+----------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Data Analyzers section\n",
    "# TODO analyze data here\n",
    "from pydeequ.analyzers import *\n",
    "\n",
    "analysisResult = AnalysisRunner(spark) \\\n",
    "                    .onData(df) \\\n",
    "                    .addAnalyzer(Size()) \\\n",
    "                    .addAnalyzer(ApproxCountDistinct(\"job_title\")) \\\n",
    "                    .addAnalyzer(Completeness(\"job_id\")) \\\n",
    "                    .addAnalyzer(ApproxCountDistinct(\"job_id\")) \\\n",
    "                    .addAnalyzer(Mean(\"min_salary\")) \\\n",
    "                    .addAnalyzer(Mean(\"max_salary\")) \\\n",
    "                    .addAnalyzer(Compliance(\"min_salary\", \"min_salary > 0\")) \\\n",
    "                    .addAnalyzer(Compliance(\"max_salary\", \"max_salary > 0\")) \\\n",
    "                    .run()\n",
    "                    #.addAnalyzer(Compliance(\"top star_rating\", \"star_rating >= 4.0\")) \\\n",
    "                    #.addAnalyzer(Correlation(\"total_votes\", \"star_rating\")) \\\n",
    "                    #.addAnalyzer(Correlation(\"total_votes\", \"helpful_votes\")) \\\n",
    "                    \n",
    "                    \n",
    "analysisResult_df = AnalyzerContext.successMetricsAsDataFrame(spark, analysisResult)\n",
    "analysisResult_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>instance</th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Column</td>\n",
       "      <td>job_id</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Column</td>\n",
       "      <td>job_id</td>\n",
       "      <td>ApproxCountDistinct</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Column</td>\n",
       "      <td>max_salary</td>\n",
       "      <td>Compliance</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Column</td>\n",
       "      <td>job_title</td>\n",
       "      <td>ApproxCountDistinct</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Column</td>\n",
       "      <td>min_salary</td>\n",
       "      <td>Mean</td>\n",
       "      <td>6568.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dataset</td>\n",
       "      <td>*</td>\n",
       "      <td>Size</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Column</td>\n",
       "      <td>max_salary</td>\n",
       "      <td>Mean</td>\n",
       "      <td>13210.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Column</td>\n",
       "      <td>min_salary</td>\n",
       "      <td>Compliance</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    entity    instance                 name         value\n",
       "0   Column      job_id         Completeness      1.000000\n",
       "1   Column      job_id  ApproxCountDistinct     19.000000\n",
       "2   Column  max_salary           Compliance      0.000000\n",
       "3   Column   job_title  ApproxCountDistinct     18.000000\n",
       "4   Column  min_salary                 Mean   6568.421053\n",
       "5  Dataset           *                 Size     19.000000\n",
       "6   Column  max_salary                 Mean  13210.526316\n",
       "7   Column  min_salary           Compliance      1.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysisResult_pandas_df = AnalyzerContext.successMetricsAsDataFrame(spark, analysisResult, pandas=True)\n",
    "analysisResult_pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'job_id':\n",
      " \tcompleteness: 1.0\n",
      "\tapproximate number of distinct values: 19\n",
      "\tdatatype: Integral\n",
      "\tmean: 10.0\n",
      "\tmax: 19.0\n",
      "\tmin: 1.0\n",
      "\tsum: 190.0\n",
      "\n",
      "Column 'job_title':\n",
      " \tcompleteness: 1.0\n",
      "\tapproximate number of distinct values: 18\n",
      "\tdatatype: String\n",
      "\n",
      "Column 'min_salary':\n",
      " \tcompleteness: 1.0\n",
      "\tapproximate number of distinct values: 14\n",
      "\tdatatype: Fractional\n",
      "\tmean: 6568.421052631579\n",
      "\tmax: 20000.0\n",
      "\tmin: 2000.0\n",
      "\tsum: 124800.0\n",
      "\n",
      "Column 'max_salary':\n",
      " \tcompleteness: 1.0\n",
      "\tapproximate number of distinct values: 13\n",
      "\tdatatype: Fractional\n",
      "\tmean: 13210.526315789473\n",
      "\tmax: 40000.0\n",
      "\tmin: 5000.0\n",
      "\tsum: 251000.0\n",
      "\n",
      "Value distribution:\n",
      "\n",
      "Column job_id\n",
      "\t\tValue 12 occured 1 times (ratio is 0.05)\n",
      "\t\tValue 8 occured 1 times (ratio is 0.05)\n",
      "\t\tValue 19 occured 1 times (ratio is 0.05)\n",
      "\t\tValue 4 occured 1 times (ratio is 0.05)\n",
      "\t\tValue 15 occured 1 times (ratio is 0.05)\n",
      "\t\tValue 11 occured 1 times (ratio is 0.05)\n",
      "\t\tValue 9 occured 1 times (ratio is 0.05)\n",
      "\t\tValue 13 occured 1 times (ratio is 0.05)\n",
      "\t\tValue 16 occured 1 times (ratio is 0.05)\n",
      "\t\tValue 5 occured 1 times (ratio is 0.05)\n",
      "\t\tValue 10 occured 1 times (ratio is 0.05)\n",
      "\t\tValue 6 occured 1 times (ratio is 0.05)\n",
      "\t\tValue 1 occured 1 times (ratio is 0.05)\n",
      "\t\tValue 17 occured 1 times (ratio is 0.05)\n",
      "\t\tValue 14 occured 1 times (ratio is 0.05)\n",
      "\t\tValue 2 occured 1 times (ratio is 0.05)\n",
      "\t\tValue 18 occured 1 times (ratio is 0.05)\n",
      "\t\tValue 7 occured 1 times (ratio is 0.05)\n",
      "\t\tValue 3 occured 1 times (ratio is 0.05)\n",
      "Column job_title\n",
      "\t\tValue Sales Representative occured 1 times (ratio is 0.05)\n",
      "\t\tValue Purchasing Clerk occured 1 times (ratio is 0.05)\n",
      "\t\tValue President occured 1 times (ratio is 0.05)\n",
      "\t\tValue Marketing Representative occured 1 times (ratio is 0.05)\n",
      "\t\tValue Finance Manager occured 1 times (ratio is 0.05)\n",
      "\t\tValue Human Resources Representative occured 1 times (ratio is 0.05)\n",
      "\t\tValue Stock Manager occured 1 times (ratio is 0.05)\n",
      "\t\tValue Stock Clerk occured 1 times (ratio is 0.05)\n",
      "\t\tValue Programmer occured 1 times (ratio is 0.05)\n",
      "\t\tValue Sales Manager occured 1 times (ratio is 0.05)\n",
      "\t\tValue Accountant occured 1 times (ratio is 0.05)\n",
      "\t\tValue Purchasing Manager occured 1 times (ratio is 0.05)\n",
      "\t\tValue Public Relations Representative occured 1 times (ratio is 0.05)\n",
      "\t\tValue Public Accountant occured 1 times (ratio is 0.05)\n",
      "\t\tValue Shipping Clerk occured 1 times (ratio is 0.05)\n",
      "\t\tValue Administration Vice President occured 1 times (ratio is 0.05)\n",
      "\t\tValue Administration Assistant occured 1 times (ratio is 0.05)\n",
      "\t\tValue Marketing Manager occured 1 times (ratio is 0.05)\n",
      "\t\tValue Accounting Manager occured 1 times (ratio is 0.05)\n",
      "Column min_salary\n",
      "Column max_salary\n"
     ]
    }
   ],
   "source": [
    "### Data profiling section\n",
    "# TODO profile data here\n",
    "from pydeequ.profiles import *\n",
    "\n",
    "result = ColumnProfilerRunner(spark) \\\n",
    "    .onData(df) \\\n",
    "    .run()\n",
    "\n",
    "for col, profile in result.profiles.items():\n",
    "    print(\"Column '{}':\\n \".format(col) +\n",
    "        \"\\tcompleteness: {}\\n\".format(profile.completeness) +\n",
    "        \"\\tapproximate number of distinct values: {}\\n\".format(profile.approximateNumDistinctValues) +\n",
    "        \"\\tdatatype: {}\\n\".format(profile.dataType) +\n",
    "        (\"\\tmean: {}\\n\".format(profile.mean) if profile.dataType == 'Integral' else '') +\n",
    "        (\"\\tmax: {}\\n\".format(profile.maximum) if profile.dataType == 'Integral' else '' ) +\n",
    "        (\"\\tmin: {}\\n\".format(profile.minimum) if profile.dataType == 'Integral' else '' ) +\n",
    "        (\"\\tsum: {}\\n\".format(profile.sum) if profile.dataType == 'Integral' else '' )\n",
    "         )\n",
    "\n",
    "print('Value distribution:\\r\\n')\n",
    "for col, profile in result.profiles.items():\n",
    "    if profile.histogram is not None:\n",
    "        print('Column {}'.format(col))\n",
    "        for each in profile.histogram:\n",
    "            print('\\t\\tValue {} occured {} times (ratio is {})'.format(each.value, each.count,round(each.ratio,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------------------------+-----------------------------------+----------------------------+\n",
      "|column_name|current_value                         |description                        |code_for_constraint         |\n",
      "+-----------+--------------------------------------+-----------------------------------+----------------------------+\n",
      "|job_id     |ApproxDistinctness: 1.0               |'job_id' is unique                 |.isUnique(\"job_id\")         |\n",
      "|job_id     |Completeness: 1.0                     |'job_id' is not null               |.isComplete(\"job_id\")       |\n",
      "|job_id     |Minimum: 1.0                          |'job_id' has no negative values    |.isNonNegative(\"job_id\")    |\n",
      "|job_title  |ApproxDistinctness: 0.9473684210526315|'job_title' is unique              |.isUnique(\"job_title\")      |\n",
      "|job_title  |Completeness: 1.0                     |'job_title' is not null            |.isComplete(\"job_title\")    |\n",
      "|max_salary |Completeness: 1.0                     |'max_salary' is not null           |.isComplete(\"max_salary\")   |\n",
      "|max_salary |Minimum: 5000.0                       |'max_salary' has no negative values|.isNonNegative(\"max_salary\")|\n",
      "|min_salary |Completeness: 1.0                     |'min_salary' is not null           |.isComplete(\"min_salary\")   |\n",
      "|min_salary |Minimum: 2000.0                       |'min_salary' has no negative values|.isNonNegative(\"min_salary\")|\n",
      "+-----------+--------------------------------------+-----------------------------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Constraint Suggestions section\n",
    "# TODO find meaninful constraints here\n",
    "from pydeequ.suggestions import *\n",
    "from pyspark.sql import Row\n",
    "\n",
    "suggestionResult = ConstraintSuggestionRunner(spark) \\\n",
    "             .onData(df) \\\n",
    "             .addConstraintRule(DEFAULT()) \\\n",
    "             .run()\n",
    "\n",
    "# Constraint Suggestions in JSON format\n",
    "#print(suggestionResult)\n",
    "suggdf = spark.createDataFrame(Row(**x) for x in suggestionResult['constraint_suggestions']) #.show(truncate=False)\n",
    "suggdf.sort(\"column_name\",\"current_value\").select('column_name','current_value','description','code_for_constraint').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+------------------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
      "|check       |check_level|check_status|constraint                                                                                                              |constraint_status|constraint_message|\n",
      "+------------+-----------+------------+------------------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
      "|Review Check|Warning    |Success     |MinimumConstraint(Minimum(job_id,None))                                                                                 |Success          |                  |\n",
      "|Review Check|Warning    |Success     |CompletenessConstraint(Completeness(job_title,None))                                                                    |Success          |                  |\n",
      "|Review Check|Warning    |Success     |CompletenessConstraint(Completeness(max_salary,None))                                                                   |Success          |                  |\n",
      "|Review Check|Warning    |Success     |CompletenessConstraint(Completeness(min_salary,None))                                                                   |Success          |                  |\n",
      "|Review Check|Warning    |Success     |UniquenessConstraint(Uniqueness(List(job_id),None))                                                                     |Success          |                  |\n",
      "|Review Check|Warning    |Success     |ComplianceConstraint(Compliance(max_salary is non-negative,COALESCE(CAST(max_salary AS DECIMAL(20,10)), 0.0) >= 0,None))|Success          |                  |\n",
      "|Review Check|Warning    |Success     |ComplianceConstraint(Compliance(min_salary is non-negative,COALESCE(CAST(min_salary AS DECIMAL(20,10)), 0.0) >= 0,None))|Success          |                  |\n",
      "+------------+-----------+------------+------------------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Constraint Verification section\n",
    "# TODO check selected constraints here and make beautify the report\n",
    "from pydeequ.checks import *\n",
    "from pydeequ.verification import *\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"Review Check\")\n",
    "\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check \\\n",
    "        .hasMin(\"job_id\", lambda x: x == 1) \\\n",
    "        .isComplete(\"job_title\")  \\\n",
    "        .isComplete(\"max_salary\") \\\n",
    "        .isComplete(\"min_salary\") \\\n",
    "        .isUnique(\"job_id\")  \\\n",
    "        .isNonNegative(\"max_salary\") \\\n",
    "        .isNonNegative(\"min_salary\")) \\\n",
    "    .run()\n",
    "\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "checkResult_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>instance</th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Column</td>\n",
       "      <td>job_id</td>\n",
       "      <td>Minimum</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Column</td>\n",
       "      <td>job_title</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Column</td>\n",
       "      <td>min_salary</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Column</td>\n",
       "      <td>job_id</td>\n",
       "      <td>Uniqueness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Column</td>\n",
       "      <td>min_salary is non-negative</td>\n",
       "      <td>Compliance</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Column</td>\n",
       "      <td>max_salary</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Column</td>\n",
       "      <td>max_salary is non-negative</td>\n",
       "      <td>Compliance</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entity                    instance          name  value\n",
       "0  Column                      job_id       Minimum    1.0\n",
       "1  Column                   job_title  Completeness    1.0\n",
       "2  Column                  min_salary  Completeness    1.0\n",
       "3  Column                      job_id    Uniqueness    1.0\n",
       "4  Column  min_salary is non-negative    Compliance    1.0\n",
       "5  Column                  max_salary  Completeness    1.0\n",
       "6  Column  max_salary is non-negative    Compliance    1.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkResult_pandas_df = VerificationResult.successMetricsAsDataFrame(spark, checkResult, pandas=True)\n",
    "checkResult_pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
